{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependancies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import linear_model as lin \n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn import metrics as met\n",
    "from sklearn import model_selection as mod\n",
    "from sklearn import pipeline as pip\n",
    "from sklearn import datasets as dat\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn import ensemble as ens\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition as dec\n",
    "from sklearn import manifold as man\n",
    "\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLearningCurve(est, X_train, y_train, X_test, y_test, n_iter=10, minY=0,maxY=1):\n",
    "    x_values = [] #number of training samples\n",
    "    y_values_train = []\n",
    "    y_values_test = []\n",
    "\n",
    "    for i in np.linspace(10,len(X_train),n_iter): #increase training sizes by every iter\n",
    "        i=int(i)\n",
    "        #select a subset of training data\n",
    "        X_train_temp = X_train[:i]\n",
    "        y_train_temp = y_train[:i]\n",
    "        #create the model\n",
    "        est.fit(X_train_temp, y_train_temp)\n",
    "        #evaluate train set\n",
    "        y_pred_train=est.predict(X_train_temp)\n",
    "        train_score = met.mean_squared_error(y_train_temp,y_pred_train,squared=False)\n",
    "        #evaluate test set\n",
    "        y_pred_test=est.predict(X_test)\n",
    "        test_score = met.mean_squared_error(y_test,y_pred_test,squared=False)\n",
    "        #populate lists\n",
    "        y_values_train.append(train_score)\n",
    "        y_values_test.append(test_score)\n",
    "        x_values.append(i)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(x_values,y_values_train,label=\"Train\")\n",
    "    plt.plot(x_values,y_values_test, label=\"Test\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xlabel(\"# of training samples\")\n",
    "    plt.grid(True)\n",
    "    plt.ylim(minY,maxY)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecisionBoundaries(clf, X, y, n_classes=2):\n",
    "  # Parameters\n",
    "  plot_colors = \"rb\"\n",
    "  plot_step = 0.02\n",
    "\n",
    "  X2 = X.values\n",
    "  y_now = y.values\n",
    "\n",
    "\n",
    "  for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                  [1, 2], [1, 3], [2, 3]]):\n",
    "      # We only take the two corresponding features\n",
    "      X_now = X2[:, pair]\n",
    "      \n",
    "      \n",
    "\n",
    "      # Train\n",
    "      clf.fit(X_now, y_now)\n",
    "\n",
    "      # Plot the decision boundary\n",
    "      plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "      x_min, x_max = X_now[:, 0].min() - 1, X_now[:, 0].max() + 1\n",
    "      y_min, y_max = X_now[:, 1].min() - 1, X_now[:, 1].max() + 1\n",
    "      xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                          np.arange(y_min, y_max, plot_step))\n",
    "      plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "      Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "      Z = Z.reshape(xx.shape)\n",
    "      cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "      \n",
    "\n",
    "      # Plot the training points\n",
    "      for i, color in zip(range(n_classes), plot_colors):\n",
    "          idx = np.where(y_now == i)\n",
    "          \n",
    "          plt.scatter(X_now[idx, 0], X_now[idx, 1], c=color,\n",
    "                      cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "  plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "  plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
    "  plt.axis(\"tight\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_roc_curve(X_train, y_train_binary, estimators=[[tree.DecisionTreeClassifier(random_state=42),\n",
    "                lin.SGDClassifier(random_state=42),\n",
    "                ens.RandomForestClassifier(random_state=42)]]):\n",
    "    for est in estimators:\n",
    "        pipe = pip.Pipeline([\n",
    "            (\"scaler\", pre.StandardScaler()),\n",
    "            (\"est\",est)\n",
    "        ])\n",
    "        if hasattr(est,\"predict_proba\"):\n",
    "            myMethod = \"predict_proba\" #returns list of lists\n",
    "        else:\n",
    "            myMethod = \"decision_function\" \n",
    "\n",
    "        y_scores = mod.cross_val_predict(pipe, X_train, y_train_binary,\n",
    "                                        cv=5, method=myMethod)\n",
    "        if myMethod == \"predict_proba\":\n",
    "            y_scores = y_scores[:, 1] #probabilities for true class\n",
    "        fpr, tpr, thresholds = met.roc_curve(y_train_binary,y_scores)\n",
    "        auc_score = met.roc_auc_score(y_train_binary,y_scores)\n",
    "        print(est.__class__.__name__,auc_score)\n",
    "        plt.plot(fpr, tpr, label=est.__class__.__name__)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.ylabel(\"tpr\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve(est, X_train, y_train_binary):\n",
    "    \n",
    "    pipe = pip.Pipeline([(\"scaler\", pre.StandardScaler())\n",
    "                         ,(\"est\",est)])\n",
    "    \n",
    "    if hasattr(est,\"predict_proba\"):\n",
    "        myMethod = \"predict_proba\" \n",
    "    else:\n",
    "        myMethod = \"decision_function\" \n",
    "    \n",
    "    y_scores = mod.cross_val_predict(pipe,X_train,y_train_binary,cv=3, method=myMethod)\n",
    "    \n",
    "    precision, recall, thresholds = met.precision_recall_curve(y_train_binary, y_scores)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(thresholds,precision[:-1], label = \"precision\")\n",
    "    plt.plot(thresholds,recall[:-1], label = \"recall\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Thresholds\")\n",
    "    plt.ylabel(\"Precision / Recall\")\n",
    "    plt.show()\n",
    "    \n",
    "    fpr, tpr, thresholds = met.roc_curve(y_train_binary,y_scores)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.ylabel(\"tpr\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
